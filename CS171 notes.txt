CS171

What is Machine Learning?
- definition by Tom Mitchell: study of algorithms that: - improve their performance P, - at some task T, - with experience E

Traditional Programming
- data + program --> computer --> output

Machine Learning
- data + desired outputs (labels) --> computer --> program

When do we use ML?
- ML is used when human expertise does not exist (e.g. navigating on Mars)
- humans can't explain expertise (e.g. speech recognition)
- models must be customized (e.g. personalized medicine)
- models based on huge amounts of data (e.g. genomics)

examples of tasks best solved by learning algorithm
- recognizing patterns:
	: facial identities/expressions
	: handwritten or spoken words
	: medical images
- generating patterns:
	: generating text, images, motion sequences
- recognizing anomalies:
	: unusual credit card transactions
	: unusual patterns of sensor reading in a nuclear power plant
- prediction:
	: future stock prices
	: weather conditions

Sample Applications: web search, computational biology, finance, social networks, robotics, etc

Defining the Learning Task
- improve the task (T) with respect to performance metric (P) based on experience (E)
	e.g. T-playing checkers, P-% of games won, E-games against itself
	e.g. T-recognizing hand-written words, P-% of words correctly classified, E-database of images of hand-written words

Applications of ML
- autonomous cars
- facial recognition
- speech recognition
- generative AI

Types of Learning
- supervised learning: given training data + desired outputs (labels)

    Regression; given (x1,y1), (x2,y2)...(xn,yn)
	learn a function f(x) to predict y given x
	- in regression: y is a real number
	i.e. given x, y could be some number (1,2,3...)

    Classification; given (x1,y1), (x2,y2)...(xn,yn)
	learn a function f(x) to predict y given x
	- in classification: y is categorical
	i.e. given x, y can be only certain categories not numbers
	- x can be multi dimensional (each dimension corresponding to an attribute)
	e.g. giving tumor size + age instead of just tumor size

- unsupervised learning: given training data (w/o desired outputs)
	: given x1, x2, ... xn (w/o labels)
	: output hidden structure behind the x's 
		(e.g. clustering, machine can see clusters are related despite no y)

    Applications
	: genomics; group individuals by genetic similarity
	: organize computng clusters
	: social network analysis
	: market segmentation
	: astronomical data analysis

- reinforcement learning: rewards from sequence of actions
	: given a sequence of states and actions with (delayed) rewards, output a policy
	    - policy is a mapping from states -> actions that tells you what to do in a given state

	Agent-Environment Interface
	- Environment receives action from Agent, Agent receives reward/state from Environment

- semi-supervised learning: given training data + some desired outputs

Designing a Learning System
- choose the training experience
- choose exactly what is to be learned
	i.e. the target function
- choose how to represent the target function
- choose a learning algo to infer the target function from the experience

Training v Test Set
- training set; subset to train a model
- test set; subset to test the trained model (unseen data)
	: both are usually drawn from the same distributed data

------------------------
Review:
- Machine Learning <p t e>: performance, task, experience

- 4 types of ML: 
	supervised: given training data + desired outputs (labels)
	unsupervised: given training data (w/o desired outputs)
	reinforcement: rewards from sequence of actions
	semi-supervised: given training data + some desired outputs

- 2 types of supervised learning:
	regression: y is a real number
	classification: y is categorical

- 2 types of unsupervised learning:
	clustering: group similar data points
	dimensionality reduction: reduce dimensionality of data

- training v test set: training set is used to train a model, test set is used to test the trained model
------------------------
Decision Trees (not usually used in production, industry uses decision tree: ensemble)
What is a Decision Tree?
- is a Supervised learning technique that can be used for both Classification and Regression problems (mostly preferred for Classification)
	e.g. Buying a car (decision tree)
		- is it a 2 door car?
			- yes: is it a sports car?
				- yes: buy it
				- no: don't buy it
			- no: is it a 4 door car?
				- yes: is it a luxury car?
					- yes: buy it
					- no: don't buy it
				- no: don't buy it

Tree Induction - challenges
1 how to classify a leaf node? 
	: assign the majority class (i.e. whichever side has the highest popularity)
2 determine how to split the records?
	: how to specify the attribute test condition?
		- depends on attribute types
			| nominal - there is no order to the values (e.g. red, green, blue)
			| ordinal - there is an order to the values (e.g. low, medium, high)
			| continuous - there is an infinite number of values (e.g. 1.2, 1.3, 1.4)
		- depends on number of ways to split
	: how to determine the best attribute to split on? (2 way/binary split | multi-way split)
		- nodes with homogeneous class distribution is preferred
		- need a measure of node impurity
			| entropy - shows randomness of data
			| gini index - shows purity of data 
			| information gain - shows how much information is gained by splitting data
3 determine when to stop splitting
	: when a node is 100% in one class
	: when splitting a node will result in the tree exceeding max depth
	: when info gain is less than threshold
	: when number of examples in node is below threshold
	: early termination

Pros 
	: inexpensive
	: extremely fast
	: easy to interpret
	: accuracy comparable to other methods

Cons
	: can create overly complex trees that do not generalize data well (overfitting)
	: highly sensitive to small changes of the data: high variance
		- small changes in data can result in large changes in tree
		- can be reduced by ensemble methods
------------------------
Review - Decision Trees
- how to determine attribute test condition?
	: attribute types, number of ways to split
- how to determine the best split?
	: homogeneous class distribution, measure of node impurity (entropy, gini index, information gain)

Bias - error between avg model prediction/truth (how well the model fits the data)

Variance - avg variability in model prediction for the dataset (how much the model changes based on the input data)

Bias-Variance Tradeoff
	: high bias, low variance
		- underfitting (overly simplified model)
		- high error on both test and train data
	: low bias, high variance
		- overfitting (overly complex model)
		- low error on train data, high error on test data
	: low bias, low variance
		- good fit
	: high bias, high variance
		- bad fit

Training and Test Errors
- training data: used to train the model
- test data: used to test the model
- test error is more important than training error (because we want to know how well the model generalizes to unseen data)
	: we care abt generalization
	: i.e. training data w no errors seems good but the test data might have a lot of errors bc the model is
		 perfect for the training but not for generalized data sets
- Generalization Errors
	: Re-substition errors: error on training (e(t))
	: Generalization errors: error on test (e'(t))
- Methods for estimating Generalization Errors
	: Optimistic approach (e'(t))
		- use training error as an estimate of generalization error
		- e'(t) = e(t)
		- problem: training error is usually optimistic
	: Pessimistic approach (e'(t))
		- use training error + complexity penalty as an estimate of generalization error
		- e'(t) = e(t) + complexity penalty
		- problem: complexity penalty is usually pessimistic
		e.g. given penality is 0.5
			Training error 10/1000 = 1%
			Generalization error (10 + 30 x 0.5)/1000 = 2.5%
		Optimistic approach (just training error) is too optimistic
		Pessimistic approach (Generalization error) is more realistic
	: Reduced error pruning (REP)
		- split training data into 2 components
			| training set - used to train the model
			| validation set - used to estimate generalization error

Overfitting
- model fits the training data too well
	: model is too complex
	: model is too sensitive to small variations in training data
	: model does not generalize well to test data
- pre-pruning
	: stop growing the tree when some stopping criteria is met
	: e.g. stop growing the tree when the number of examples in a node is below a threshold
- post-pruning
	: grow the tree to completion, then prune the tree
	: e.g. if removing a sub-tree improves generalization error (reduces), then replace sub-tree with leaf node
		- the class label of that leaf node is the majority class of the sub-tree

Model Evaluation in Classification
- metrics for Performance Evaluation
	: predictive capability - how well does the model predict the class label of unseen data?
		- confusion matrix
			| TP - true positive 
			| TN - true negative 
			| FP - false positive (model predicts positive but is actually negative)
			| FN - false negative (model predicts negative but is actually positive)
	: accuracy
		- fraction of correct predictions
		- accuracy = (TP + TN)/(TP + TN + FP + FN) == (true predictions)/(total predictions)
		- can be misleading, e.g. if 99% of data is class A, then a model that always predicts class A will have 99% accuracy
	: precision
		- fraction of positive predictions that are correct
		- precision = TP/(TP + FP) == (true positive predictions)/(total positive predictions)
	: recall
		- fraction of positive examples that are correctly predicted
		- recall = TP/(TP + FN) == (true positive predictions)/(total positive examples)
	: F1 - measure = 2 * (precision * recall)/(precision + recall)
	: ROC curve
		- plots true positive rate (TPR) vs false positive rate (FPR)
- methods for Performance Evaluation
	: estimation
		- holdout method (2/3 data for training, 1/3 data for testing)
			| split data into training and test sets
			| train model on training set
			| evaluate model on test set
		- random subsampling 
			| repeated holdout method
		- cross validation (k-fold cross validation)
			| split data into training and testing
			| training is broken into k equal sized subsets
			| e.g. fold 1 is for validation, fold 2-5 is for training, then fold 2 is for validation, fold 1,3-5 is for training, etc
				- imagine validation data as a mini-test data inside the training data	
			| repeat k times, each time using a different subset for testing
		- bootstrap
			| randomly sample data with replacement
			| train model on sampled data
			| evaluate model on unsampled data

------------------------------------------------
Ensemble Learning
- weak learner/classifier - learning algo that performs slighly better than chance (e.g. correctly labels ~.6)

(Accuracy v Efficiency -------------------------)
| accuracy - true predictions/total predictions |
| efficiency - complexity, time, space			|
(-----------------------------------------------)

- Why use Ensemble Learning?
	: can combine weak learners to create a strong learner
	: basic ensemble functions
		- max voting (classification - discrete)
			| class with the most votes is the predicted class
		- averaging (regression - continuous)
			| average of all predictions is the predicted value
		- weighted averaging (regression)
			| each learner is given a certain weight and thus higher weight have more influence on the final prediction

- What is bagging? (bootstrap aggregating)
	: multiple weak learners are trained in parallel (each learner is independent of each other)
	: each weak learner has input data randomly sampled from the original dataset with replacement
	: final prediction is the average of all weak learners
	: reduces variance (how much the model changes based on input data)
	: reduces overfitting (model fits training data too well)

- What is boosting?
	: multiple weak learners are trained in sequence (each learner is dependent on each other)
		- think of it as a chain of weak learners where each sequential learner has more information than the previous learner (weights of mistakes from prior learner)
	: each subsequent model is trained by giving more weight to examples that were misclassified by previous models
		- e.g. if model 1 misclassified 10 examples, then model 2 will give more weight to those 10 examples
	: final prediction is chosen by scaling each weak-learner's prediction by its weight (why give weight to wrong answers?)
	: reduces bias (error between avg model prediction/truth - how good the model is at predicting the data)

- What is stacking?
	: multiple weak learners (different types) are trained in parallel (each learner is independent of each other)
	: does not use simple voting for final prediction
	: creates a meta learner trained on the outputs of the weak learners
	: 2 subsets of the training data
		- one for training the weak learners
		- one for training the meta learner (weak learners are fed the data then the output is fed to meta learner)

Summary of Ensemble Methods (you can combine based on the problem)
	: bagging - reduces variance, simple voting
	: boosting - reduces bias, weighted voting
	: stacking - improves accuracy, learned voting	

Decision Tree Ensemble Methods
	: issues with decision trees - (over/under fitting)

	Random Forest
		- bagging algo on decision trees
			1. pick N random records from data set (bootstrap)
			2. build a decision tree based on the N records
			3. repeat steps 1-2 k times to make k trees
			4. each tree predicts the class label of the prediction, majority class wins
	Pros
		: used for classification & regression
		: works well w categorical/numerical data, no scaling or transformation required
		: generally provides high accuracy and balance the bias-variance trade off
	Cons
		: not easily interpretable
		: computationally intense
		: like "black box" algo, little control over what model does

	(Bootstrap v Cross Validation (kfold) -------------------------------------)
	| Bootstrap - sampling with replacement (can have overlap/reused data)	   |
	| Cross Validation - sampling without replacement (no overlap/reused data) |
	(--------------------------------------------------------------------------)

	Gradient boosting (how is it different from regular boosting?)
		- Boosting algo on decision trees
			: calculates loss function, updates model parameters in direction that reduces loss function the most
			: final prediction is obtained by adding up the projections of each individual tree
	Pros
		: used for classification & regression
		: helpful for managing complicated heterogenous data and enhancing model correctness
		: can handle categorical and continuous vars
		: high prediction accuracy 
	Cons
	: computationally expensive
	: overfitting

	(Heterogeneous v homogeneous Data set --------------------------------------)
	| Heterogeneous can have different types, e.g. numerical and categorical 	|
	| Homogeneous can only have one type, e.g. all numerical or all categorical |
	(---------------------------------------------------------------------------)

	XGBoost (extreme gradient boosting)
		- Boosting algo on decision trees
			: custom loss function 
			: main diff between Gradient and XG - uses regularization technique
		- performs better than Gradient bc of regularization
		- utilizes CPU parallel processing
		- 2 main components
			: tree boosting - builds trees one at a time, each tree is built to correct the errors of the previous tree
			: regularization - penalizes more complex models

	AdaBoost (Adaptive Boosting)
		- Decision Stumps (decision trees with only 1 split)
		- weak learner needs to minimize weighted error
		- more intuitive than Gradient but Gradient is more flexible (generic algo)
		- AdaBoost is slower bc needing multiple iterations to build the sequence of models
		- AdaBoost is more abt "voting weights" (?)
		- Gradient is more abt "adding gradient optimization" (?)

Summary
	: bagging 
		- cut training data into subsets (one subset per learner)
		- train weak learners in parallel (each their own subset)
	: boosting
		- entire training data per learner
		- weak learners are trained in sequence, subsequent learner takes weights from previous learner's mistakes
	: stacking
		- 2 subsets of training data (one for learners, one for meta learner)
			: learners are trained in parallel (training)
			: meta learner is trained on the outputs of the learners (trained)
	------------------------
	new types
		: random forest - bagging algo on decision trees
			- 
		: gradient boosting - boosting algo on decision trees
		: XGBoost - extreme gradient boosting
		: AdaBoost - adaptive boosting
------------------------
Review
- Supervised Learning - given training data + desired outputs (labels)
	: regression - y is a real number
	: classification - y is categorical
- Ensemble Learning - combining multiple weak learners to create a strong learner
	: bagging - reduces variance, simple voting
	: boosting - reduces bias, weighted voting
	: stacking - improves accuracy, learned voting

------------------------
Parametric ML algo - summarizes data w set of parameters of a fixed size
	: 2 steps
		1. select a form for the function
		2. learn coefficients for the function from training data
	: examples - linear regression, logistic regression, linear discriminant analysis, naive bayes, simple neural networks
	Pros
		: simple (easy to understand/interpret)
		: fast (when learning from data)
		: less training data required
	Cons
		: less flexible (constrained to specific form )
		: limited complexity (more suited to simpler problems)
		: poor fit (unlikely to match true underlying function [imagine a linear function trying to fit a quadratic function])

Non-parametric ML algo - does not summarize data w set of parameters of a fixed 
	: good when a lot of data and no prior knowledge
	: when you don't want to worry abt choosing the right features
	: seek best fit to training data
		- constructing the mapping function while maintaining the ability to generalize unseen data
		- e.g. K-Nearest Neighbors (KNN), decision trees, support vector machines
	Pros
		: flexible (not constrained to specific form)
		: powerful (no assumption abt underlying function)
		: performance (high perf models for prediction)
	Cons
		: slow (when learning from data)
		: more training data required
		: overfitting (more likely to overfit training data)

( try drawing the circles with each algo inside each to see how they relate )-----------------

K-Nearest Neighbors (KNN) [non-parametric supervised learning]
- one of the simplest ML classifier algo
- Simple Idea: label a new pt the same as closest known pt
- type of Instance-Based learning (memory based)

How does KNN work?
	: given set of labeled pts (training data) and a new pt (test data)
	: find k closest pts in training data and label new pt accordingly
		- e.g. given 2 classes (red, blue) and k = 3
			| 2 red pts, 1 blue pt
			| new pt is red bc 2/3 closest pts are red (if all classes [colors] given equal weight)
	
Who gets to vote?
	: "national" election, majority rules and most numerous class wins
		- no universal suffrage for k-NN
	: "local" election used for k-NN, nearest k pts

How to count (weight) the votes?
	: weight by distance
		- closer pts have more influence on the prediction
		- weight is proportional to the inverse of the distance (1/distance(k pt))
		- sum inverse distances together to get weight of class (e.g. 1/r1 + 1/r2 vs 1/b1)
		- Distance metrics/formulas
			| Euclidean Distance - straight line distance
			| Manhattan Distance - sum of absolute differences
			| Minkowski Distance - generalized distance metric of both Euclidean and Manhattan
			| Cosine Distance - angle between vectors
			| Jaccard Distance - similarity between sets
	: weight by class frequency (use all pts in the graph)
		- e.g. 2 red, 1 blue in k = 3
			| 10 red total, 4 blue total
	: weight by fixed radius (pts within radius are given weight, pts outside radius are not given weight)
		- the mode (most common class) is the predicted class
		- good for sparse data
	
How to choose K in KNN?
	: based on input data
	: if input has outliers or noise, higher is better
	: cross-validation (k-fold) to find optimal k

KNN - Pros
	: no training required
	: computations deferred to scoring phase
	: as training size grows, accuracy increases
	: works for multi-class problems
		- e.g. given 3 classes (red, blue, green)
	: easy to implement (low complexity)

KNN - Cons
	: scoring is not straightforward
		- calculate all distances to all points needed for score computation
	: very sensitive to local structure of data
		- e.g. if data is clustered, then KNN will be biased towards the cluster
	: does not scale well (time consuming to calculate distances if data set is large)
	: Curse of Dimensionality
		- hard time classifying data pts when dimensionality is too high
		- dimensionality: number of features
	: prone to overfitting

KNN - Summary
	: non-parametric supervised learning
	: simple
	: lazy learning (no training required)
	: can be combined w other techniques like PCA 
------------------------
Review:
supervised learning
	: regression - output is real number
	: classificaiton - output is categorical

decision tree
knn
------------------------
Linear Regression (parametric supervised learning)
- conditions for accurate soln
	: linearity (relationship between x-independent and y-dependent is linear)
	: independence (x's are independent of each other)
	: homoscedasticity (amt of x-independent has no impact on variance of errors)
	: normality (normally distributed)
	: no multicollinearity (x's are not correlated w each other)
- simple linear regression
	: y = mx + b
	: dependent var dependent on only 1 independent var
	: sloped line is called regression line
- multiple linear regression
	: dependent var depends on more than 1 independent var
- R-Squared (R^2)
	: measures how well the regression line fits the data
	: R^2 = 1 - (SSres/SStot)
		| SSres - sum of squared residuals (sum of squared errors)
			- (yi - yhat)^2; yi - actual value, yhat - predicted value
		| SStot - total sum of squares (sum of squared differences from mean)
			- (yi - yavg)^2; yi - actual value, yavg - avg value
- Residual Sum of squares (Loss function)
	: goal is to minimize RSS
	: RSS = sum of (yi - yhat)^2
	: gradient i.e. partial derivative of loss function
	: gradient descent - iterative optimization algo to find min of a function
		- take repeated steps in opposite direction of gradient of function at the current points
		| types
			- batch gradient descent (uses entire training set to compute gradient)
			- mini-batch gradient descent (uses a subset of training set to compute gradient)
			- stochastic gradient descent (uses 1 training example to compute gradient)
	: Frontpropagation - forward pass of data through the network
	: Backpropagation - backward pass of data through the network

Linear Regression - Pros
	: simple
	: less complexity
	: dimensionality reduction, regularization, cross validation avoids overfitting

Linear Regression - Cons
	: outliers have huge effects
	: assumes independence between attributes
	: not a complete description of relationship among vars

	(App Idea (parking @ sjsu) ----------------------------------)
	| pull parking data and store on graph (similar to cs171)	 |
	| create avg time for parking per time periods (5mins)		 |
	| possibly allow user to put preferred time arrival and show |
	| probability of finding parking spot						 |
	| additionally, show probable floor?						 |
	(------------------------------------------------------------)

------------------------
Review
Supervised Learning - Y=f(X)
	: classification - output is categorical
	: regression - output is continuous

Logistic Regression (parametric supervised learning)
	: used for classification
		- examples: email spam or not spam, tumor malignant or benign, online transaction is fraudulent
	: cannot be used for classification problems unless probability is used
		- e.g. if given ages and true/false in having disease, cannot use. but if given ages and % of true/false of having disease, it is possible.
	
	Binary classification (one or the other)
	: Sigmoid function
		| maps any real value to a value between 0 and 1
		| used to transform linear combinations of predictors into probabilities


	Multi-Class classification (3+ classifications)
	: use softmax function to calculate

	Log Odds
	: Odds Ratio = p / 1 - p (p = probability of event)
	: logistic regression assumes log odds is linear function of x

	Logistic Regression - Objective Function (Loss Function - RSS)

	Maximum Likelihood Estimation (MLE)
	: used to estimate parameters of a probability distribution by maximizing a likelihood function

	Gradient Descent for Logistic Regression
	: gradient descent is used to minimize the loss function

	Logistic Regression - Pros
	: easier to implement, interpret, and very efficient to train
	: no assumptions abt distributino of classes
	: easy to extend to multi-classes
	: fast at classifying unknown records

	Logistic Regression - Cons 
	: prone to overfitting
	: if # of observations is less than # of features, model will overfit
	: creates linear boundaries
	: can only be used to predict discrete functions

------------------------

Data Preprocessing
Why Preprocess?
: real world data is dirty
	- incomplete, noisy (errors/outliers), inconsistent (discrepancy in codes/names), duplicate, irrelevant, redundant

Data Cleaning
: fill in missing values, smooth data, identify/remove outliers, resolve inconsistencies
: tasks
	- fill in missing values
		| many tuples have no recorded value for several attributes, e.g. age, income, etc
		| equipment malfunction
		| data entered incorrectly/not important at time of entry
		: ignore missing data
		: fill manually
		: use global constant (e.g. 'Unknown' class)
		: use attribute mean 
		: use most probably value
	- identify outliers
	- smooth noisy data
		| faulty instruments, data entry problems, etc
		: Binning method
			- sort data and partition into bins
			- smooth by bin means, median, or boundaries
			: equal-width partitioning
				- range of values divided into N intervals of equal size
				- width = (max - min) / N
			: equal-depth partitioning
				- range of values divided into N intervals with equal number of values in each bin
				- depth = (total # of values) / N
		: Clustering method
			- smooth by cluster means, median, or boundaries
	- correct inconsistencies

Data Integration
: integrate multiple databases, data cubes, files, etc
: may have rendundant info, e.g. age in customer table and age in loan table

Data Transformation
: normalization - scaling to specific range
	- min-max normalization
		| scale values to range [new_min, new_max]
		| new_value = (old_value - min)/(max - min) * (new_max - new_min) + new_min
	- z-score normalization
		| scale values to have mean = 0 and std dev = 1
		| new_value = (old_value - mean)/std_dev
	- decimal scaling
		| scale values to range [0, 1]
		| new_value = old_value/10^j
		| j = spaces of max value to left of decimal point (e.g. 1000 -> 4 to get .1000) or (e.g. 485 -> 3 to get 0.485)
: aggregation - summary or aggregation operations on data (sum, min, max, average, etc)
: smoothing - remove noise from data (e.g. binning, clustering)
: generalization - transform low lvl data to high lvl attributes w hierarchy
: attribute/feature construction - new attributes constructed from given ones (e.g. age to age group)

Data Reduction
: reduce volume but produce similar results (if large dataset, long time to train)
: Dimensionality reduction
	- remove irrelevant, redundant, or noisy attributes
	- select min set of attributes whose probability distribution is as close as possible to original probability distribution
	- Forward Selection - start w empty set, add 1 attribute at a time (attribute w best accuracy/most relevant)
	- Backward Elimination - start w all attributes, remove 1 attribute at a time (attribute w worst accuracy/least relevant)
	- Principal Component Analysis (PCA)
		| large set -> smaller set by selecting subset of attributes that capture most of info
		| 1st principal component - direction of max variance, 2nd pc - direction of 2nd max variance, etc
: Discretization/Quantization
	- 3 types of attributes: 1. nominal (no order), 2. ordinal (order), 3. continuous (real numbers)
	Discretization/Quantization
	- divide range of continuous into intervals
	- replace attribute values w interval labels
		| e.g. age -> young, middle-aged, senior
: Sampling
: Data compression
: Data Cube aggregation

Imbalanced Data
: large discrepancy between # of examples w each class label
| e.g. 99% of data is class A, 1% of data is class B
| e.g. medical diagnosis (majority are healthy thus always predict healthy), rare events like earthquakes, fraud detection, etc
: evaluation
	- accuracy is not a good measure
: Undersampling
	- randomly remove examples from majority class until balanced
	| e.g. 99% A, 1% B -> 50% A, 50% B
	Pros: easy to implement, training more efficient
	Cons: throwing away a lot of data/information
: Oversampling
	- randomly duplicate examples from minority class until balanced
	| e.g. 99% A, 1% B -> 50% A, 50% B
	Pros: easy to implement, utilize all training data, no data lost
	Cons: computationally expensive to train classifier, overfitting
: Weighted examples
	- assign higher weights to minority class examples, majority % / minority % = minority weight
	| e.g. 99% A, 1% B -> 99/1 = 99 -> A weight = 1, B weight = 99

------------------------
Regularization

Review
: Linear Regression - sum of weighted independent vars (e.g. y = w1x1 + w2x2 + b)
	- cost function - RSS + regularization term
	- gradient descent - minimize loss function
: Logistic Regression - sigmoid function (e.g. y = 1/(1 + e^-(w1x1 + w2x2 + b)))
	- cost function - negative log likelihood + regularization term
	- gradient descent - minimize loss function
: Underfitting - not enough features (i.e. not enough weights) thus model is too simple
	- fails to capture underlying trend of data
	- high bias
: Overfitting - too many features (i.e. too many weights) thus model fits training data too well
	- fails new examples/test cases
	- high variance
: Bias-Variance Tradeoff 
	- bias - difference between prediction/truth (how well the model is working)
	- variance - how spread the prediction is from the mean data (how much the model changes based on the input data)

Addressing Overfitting
1. getting more training data
2. reduce # of features
3. regularization, reduce magnitude/importance of features

Regularization
: modify loss function
: add regularization term that penalizes some specific properties of model parameters
: when lambda is very large = underfitting
: when lambda is very small = overfitting
	L1 Regularization - LASSO
	: penalizes the absolute value of the parameter magnitude
	L2 Regularization - Ridge Regression
	: penalizes the square of the parameter magnitude

Pros 
: reduces overfitting
: if large multivariante data, works well

Cons
: includes all predictors, even if not relevant
: shrink coefficient towards 0
: trades variance for bias
------------------------
Support Vector Machines (SVM)
: Linear classifier
: Classifier margin - distance between classifier and nearest datapoint (before hitting datapoint)
	Maximum Margin (SVM/LSVM)
	- to find optimal classifier, maximize margin (enlargen margin around line before hitting datapoint)
	- Support Vectors - points that define the margin (the ones on the edge of the line's margin)
	- Hyperplane - line that separates the classes (if p-dimensions, Hyperplane is flat affine subspace of dimension p-1)
		| affine - doesn't intersect the origin
		| e.g. 2d -> line through graph, 3d -> plane (paper thin) through 3d graph
		- Hyperplane equation - w1x1 + w2x2 + ... + wnxn + b = 0
			| w1, w2, ..., wn - weights
			| x1, x2, ..., xn - features
			| b - bias
			: given point X
				point on hyper plane if p-dimensional space equation = 0
				point above hyper plane if p-dimensional space equation > 0
				point below hyper plane if p-dimensional space equation < 0
		- to find optimal hyperplane:
			: compute perpendicular distance from each training observation to a given hyperplane
			-> smallest distance is minimal distance from observation to the hyperplane and is known as the margin
	? - so would the typical margin just be 0 or close to 0
	? - would maximum margin contain any datapoints or no, bc then minimal distance to hyperplane is basically 0 / worthless
	( think of this as inflating a suit around the line and the support vectors are like pegs to hold it from expanding too much )

	Non-separable case
	- many cases, it is unable to have separating hyperplane (i.e. no maximal margin classifier)
	-> Soft-Margin - allow some points to be on the wrong side of the margin (i.e. allow some misclassifications)

	Support Vector Classifier (Soft-Margin)
	- allow some points to be on the wrong side of the hyperplane
		: slack variables - tells us where the point is in relation to the margin
			| if slack variable = 0, point is on the correct side of the MARGIN
			| if slack variable > 0, point is on the wrong side of the MARGIN
			| if slack variable > 1, point is on the wrong side of the HYPERPLANE
		: C - penalty parameter (how much to penalize misclassifications)
		-> large C = high tolerance for wrong classifications, large margin (low variance, high bias)
		-> small C = low tolerance for wrong classifications, small margin (high variance, low bias)
	
	Some cases cannot use Linear boundaries -> quadratic, cubic, other polynomials, etc

------------------------
StatQuest w Josh Starmer (SVM p1)
SVM main idea - 
1. start in low dimension
2. move data into higher dimension (e.g. 1d -> 2d (square it), 1d -> 3d (cube it))
3. find SVC (support vector classifier) that separates the higher dimensional data into 2 groups
-> SVC = hyperplane in higher dimension

2 - how to know how to modify data (e.g. squaring it for 1d -> 2d, etc)
-> Kernel Functions - systematically find SVC in higher dimensions
	- relationships between each pt used to find SVC

Polynomial Kernel (d = degree of the polynomial)
- d=1; compute relationship between each pair of point in 1d
- d=2; compute relationship between each pair of point in 2d (squared)
- find good d value by using cross validation

Radial Basis Function Kernel (RBF)
- functions similar to K nearest neighbors

The Kernel Trick
- reduces computation by avoiding transforming data into higher dimensions
-> calculates "as if" the data is in higher dimension
------------------------
Kernel Trick 
- reduces computation by avoiding transforming data into higher dimensions
- inner product of two vectors
: kernel function - quantifies similarities between two observations
: Linear Kernel - summation of inner products of each feature
: Polynomial Kernel - inner product of each feature raised to a power
: Radial Kernel - exponential of a negative gamma value multiplied by inner product of each feature
	-> has very local behavior

Advantages
- computationally efficient

SVM with 2+ classes
- 2 popular approaches to extend SVM to k-classes
	: one versus one
	: one versus all

Bayes' Rule 
- conditional probability
- P(A|B) = P(B|A) * P(A) / P(B)

Independence Formulation
- P(A|B) = P(A) * P(B|A) / P(B)

Conditional Independence Formulation
- P(A|B) = P(A) * P(B|A) / P(B|C) * P(C|A) + P(B|~C) * P(~C|A)

========================
Essential Probability Functions
- Bayes Rule
- Conditional Probability
- Joint Probability
- Marginal Probability
- Independence
- Conditional Independence
- Expectation

Density Estimation 
- Input Attributes => Density Estimation -> Probability

Naives Bayes summary

========================
ML Applications: Text Classification e.g. Spam Email filtering

Dictionary: set of all possible words

Representations
-> bag of words: treat each document as sequence of words 
	- document d => vector of word counts (# of each word)

Term Frequency: measure of importance of term t to document d
-> boolean - 1 if appeared in d, 0 if not
-> raw count - # of t occuring in d 
-> log-scaled counts - 1 + log(raw count)
-> normalized counts - raw count / total # of words in d

========================
Intro to Neural Networks 

AI contains ML which contains Deep Learning 
DL c ML c AI 

Early Stopping (combine these 2 rules)
-> stop when validation loss increases
-> stop when training loss becomes very small 

========================
Review: Neural Networks
- perceptron: single layer neural network (input layer -> hidden layer -> output layer)
- hidden layer --> dot product of inputs and weights + bias
- Backpropagation = learning 

Convolutional Neural Networks (CNN)
- used mainly for image classification
- multi-layer neural network with 
	1. local connectivity
		> local = each neuron is connected to a small subset of neurons in previous layer (as long as it's not all of them)
		> global = every layer can be connected to every other node in other layer (e.g. fully connected)
	2. weight sharing
		> each neuron in a layer shares the same weights (e.g. w1, w2, w3 max)
		> no weight sharing, each connection has their own weight (e.g. w1-wn)
	3. input channels
		> single = inputs from one layer (b/w img = 2d array, x -> y)
		> multi = inputs from multiple layers (colored img = 3d array, x1 -> y and x2 -> y)
	4. output maps
		> single = one output layer (x -> y)
		> multi = multiple output layers (x -> y1 and x -> y2)

	S1 Convolutional layer -> apply kernel/filters on img to get feature maps
		?? how do you decide the feature detector/filter ?? --> im assuming you do cross validation to see what detector is the best
		--> many feature filters applied to one img to get many feature maps (e.g. detect certain features and apply to img to find those features)

	S1.5 Apply Rectifier activation function (ReLU) on feature map 
		(negative vals are filtered out, positive vals are left alone)
	
	S2 Pooling - applies variance over original img (spatial invariance)
		--> doesn't care abt orientation or where features are, as long as there are features 
		--> reduces size of img (e.g. 2x2 pooling = 4 pixels -> 1 pixel)
		--> pick max value in each region (max pooling)
	
	S3 Flattening --> flatten img (e.g. matrix 3x3) into 1d array (e.g. 1x9),
	
	S4 Full Connection output of S3 = input for ANN (Artificial Neural Network)

	- normalization: subtract mean, divide by standard deviation of activations w/in mini batch 
	- Dropout: used to reduce overfitting (randomly drop neurons during training)

========================
Natural Language Processing
- difficulties:
	> ambiguity of language
	> contextual information in sentences
	> cannot understand creativity
	> no direct mapping between vocabularies between any languages
- ML in regards to NLP
	> ML, programmer must extract features then training of classification nodes is done
		- easier to explain but lack expressive power
	> DL, extraction of features and training of classification nodes are together
		- more expressive but harder to explain (blackbox)
- word embedding: convert words into vectors to be understood by machines 
	> One-Hot Encoding - each word is represented by a vector of 0s and 1s
		e.g. "Milo is a cat", "A cat eats fish", "Milo eats fish" 
		1 = word is present, 0 = word is not present
				Milo - (1,0,0,0,0,0)
				is - (0,1,0,0,0,0)
				a - (0,0,1,0,0,0)
				cat - (0,0,0,1,0,0)
				eats - (0,0,0,0,1,0)
				fish - (0,0,0,0,0,1)
			>> Milo is a cat   = (1,1,1,1,0,0)
			>> A cat eats fish = (0,0,1,1,1,1)
			>> Milo eats fish  = (1,0,0,0,1,1)
		CONS
		- no word similarity, you can mix up the sentence and still return the same value
		- sparse (lots of 0's)
		- high dimensionality/size of vectors (e.g. 100,000 words = 100,000 dimensions)
	> Word2Vec - represent words as dense vectors in a continuous space (captures semantic relationship)
		- words must be "close" in Euclidean sense (e.g. cloud - sky < cloud - steak = smaller if related, larger if not)
		- arithmetic should be possible (e.g. King - Man + Woman = Queen)
		- dense vector = example like 50 vectors between -1.6-1.6 (e.g. 0.1, 0.2, 0.3, etc)
		- 2 versions
			> CBOW (Continuous Bag of Words) - predict word given context (surrounding words)
				- order of surrounding words doesn't matter, faster
			> Skip-gram - predict context given word
				- order matters, better job for infrequent words
		CONS
		- unable to capture polysemy (multiple meanings of a word)
		- needs large dataset
		-> pre-trained models address some Word2Vec limitations


Deep Learning NLP ----------------------------
> Recurrent Neural Network
    - networks must understand full sentences (sequential data) -> "normal" deep learning cannot do this 
    > new architecture that introduces concept of state
        - e.g. "bologne wasn't authentic, but bread was" versus "bread wasn't authentic, but bologne was" (same words, diff meaning)
        - state allows us to keep track of what we've seen before
        > have network per each time step (e.g. 1st word, 2nd word, 3rd word, etc.) -> time in this case refers to set of inputs at a given point
            - each network has a hidden state that is passed to the next network (internal state/cell state - h1)

[Activation Function - function that is applied to the output of each neuron in a neural network]

    - Backpropagation Through Time (BPTT)
        > can lead to vanishing gradient problem (gradient becomes too small to be useful)
        
> Long Short Term Memory (LSTM)
	> Forget, Store, Update, Output
		- works better than RNN w long sentences but if too long -> doesn't work -> use Attention 
			> Attention (2017): each state has access to each other state in the sentence 

> Transformers (Attention is base of this)

========================
Unsupervised Learning 
-- Clustering --
> supervised - provide input and (correct labels) output data, versions of supervised learning being how much answer data is provided
> unsupervised - provide input data and no output data, no labels, no answers, no teacher
	- goal is to find patterns in data
	- e.g. clustering, dimensionality reduction, etc
> goal of clustering - group similar data points together
	- clusters are represented by a point (centroid)
		> centroid = mean of all points in cluster
	- cluster boundary decided by farthest data point from centroid
> types of clustering 
	- exclusive (k means)
		> idea: randomly initialize k cluster centers, iterate between 2 steps until convergence
			1. assign each data point to closest cluster center
			2. update cluster centers to be mean of all data points assigned to it
		> pros 
			- simple, fast to compute
			- converges to local min 
		> cons
			- choose k?
				> visualization method (common), pick manually
				> elbow method
			- sensitive to initial centers
			- sensitive to outliers
			- detects spherical clusters
			- assumes mean can be computed
	- overlapping (fuzzy c means)
		> idea: each data point has a degree of membership to each cluster
			- e.g. data point 1 = 0.2 cluster 1, 0.8 cluster 2
			1. randomly initialize cluster centers
			2. compute degree of membership for each data point
			3. update cluster centers to be weighted mean of all data points
		> pros
			- allow data points to be in multiple clusters 
			- more natural representation of behavior of genes 
		> cons 
			- need to determine c (k in k-means), # of clusters 
			- need to determine membership cutoff value
			- clusters are sensitive to initial assignment of centroids
	- hierarchical (divisive clustering)
		> idea: tree-like where clusters are merged or divided depending on the method 
		> agglomerative (bottom up) clustering
			> builds from  bottom level, merge similar/nearest pair of clusters, stops when all clusters merged into single root 
		> divisive (top down) clustering 
			> builds from top level, divide clusters into smaller clusters, stops when each cluster is a single data point
		> pros 
			- dendogram is useful for visualization
			- provides hierarchical relations between clusters
			- shown to be able to capture concentric clusters 
		> cons 
			- need to determine # of clusters
			- sensitive to outliers
	- probabilistic (expectation maximization)
		> idea: each data point has a probability of belonging to each cluster
			- e.g. data point 1 = 0.2 cluster 1, 0.8 cluster 2
			1. randomly initialize cluster centers
			2. compute probability of each data point belonging to each cluster
			3. update cluster centers to be weighted mean of all data points
> clustering functions 
	- similarity functions/distance measures (e.g. Euclidean, Manhattan, etc)
	- stopping criteria 
		> no re-assignment of data point to diff cluster
		> no change of centroid 
		> minimum decrease of sum of squared error (SSE)
	- cluster quality 
		> inter-cluster distance (distance between clusters)
		> intra-cluster distance (distance between data points within clusters)
> cluster evaluation 
	- difficult bc no ground truth (no specific answer for where the centroids/clustering should be)
	- user inspection (visualize clusters)
	- use labeled data (assuming each class is a cluster) 
		> create confusion matrix and analyze metrics like precision, recall, f1 score, etc.
		
========================
Reinforcement Learning
- agent interacting w environment which provides numeric reward signals
- goal is to learn how to take actions to maximize reward

> Markov Decision Process (Environment)
	> each time step s:
		> choose Action a from set As
		> move to new state w probability: Pa(s,s')
		> receive reward Ra(s,s')
	- only cares abt current state + current set of actions

> Policy (Behavior of Agent)
	- pi(s) = action to take in state s 

- Challenges for RL 
	> many actions/states
	> if episode can end w/o reward 
	> narrow path to goal

> Q-Learning
	> start random state (s)
	> random action (s -> s')
		> update Q-table based on reward of current state
	> repeat random action + update until goal state reached	
	- Q-Table: table of all possible states and actions w their respective rewards
	- Q-Learning Challenges
		> if state space is continuous 
			- must approximate Q by discretizing (dividing continuous space into finite discrete states)
		> treats states as identities (no knowledge on how states relate)
		> converging Q can be difficult bc of random transition/rewards


Gym - Toolkit for RL 
(== game that uses AI learning to create level that player must beat? example: small 10 x 10 room, path player took, AI place block, etc==)
<== maybe Game where you're making the Death Star path to the core (play on how it was simple so making path complicated and hard) --> can play as either side ==>